@misc{bge_embedding,
      title={C-Pack: Packaged Resources To Advance General Chinese Embedding},
      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},
      year={2023},
      eprint={2309.07597},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{li2023angle,
  title={AnglE-optimized Text Embeddings},
  author={Li, Xianming and Li, Jing},
  journal={arXiv preprint arXiv:2309.12871},
  year={2023}
}

@article{muennighoff2022mteb,
    doi = {10.48550/ARXIV.2210.07316},
    url = {https://arxiv.org/abs/2210.07316},
    author = {Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"\i}c and Reimers, Nils},
    title = {MTEB: Massive Text Embedding Benchmark},
    publisher = {arXiv},
    journal={arXiv preprint arXiv:2210.07316},
    year = {2022}
}

@article{lee2019biobert,
  abstract = {{Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora.We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62\\% F1 score improvement), biomedical relation extraction (2.80\\% F1 score improvement) and biomedical question answering (12.24\\% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts.We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.}},
  added-at = {2020-03-02T10:05:52.000+0100},
  author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  biburl = {https://www.bibsonomy.org/bibtex/2d7abd453c64cb18c53fc44a40abd28cb/nosebrain},
  doi = {10.1093/bioinformatics/btz682},
  eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/4/1234/32527770/btz682.pdf},
  interhash = {41a44b7a31aa65225da21380730cf3fb},
  intrahash = {d7abd453c64cb18c53fc44a40abd28cb},
  issn = {1367-4803},
  journal = {Bioinformatics},
  keywords = {bert biobert clinic lm},
  month = {09},
  number = 4,
  pages = {1234-1240},
  timestamp = {2020-03-19T17:08:00.000+0100},
  title = {{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}},
  url = {https://doi.org/10.1093/bioinformatics/btz682},
  volume = 36,
  year = 2019
}

@article{Dogan2014-rh,
  title    = "{NCBI} disease corpus: a resource for disease name recognition
              and concept normalization",
  author   = "Do{\u g}an, Rezarta Islamaj and Leaman, Robert and Lu, Zhiyong",
  abstract = "Information encoded in natural language in biomedical literature
              publications is only useful if efficient and reliable ways of
              accessing and analyzing that information are available. Natural
              language processing and text mining tools are therefore essential
              for extracting valuable information, however, the development of
              powerful, highly effective tools to automatically detect central
              biomedical concepts such as diseases is conditional on the
              availability of annotated corpora. This paper presents the
              disease name and concept annotations of the NCBI disease corpus,
              a collection of 793 PubMed abstracts fully annotated at the
              mention and concept level to serve as a research resource for the
              biomedical natural language processing community. Each PubMed
              abstract was manually annotated by two annotators with disease
              mentions and their corresponding concepts in Medical Subject
              Headings (MeSH\textregistered{}) or Online Mendelian Inheritance
              in Man (OMIM\textregistered{}). Manual curation was performed
              using PubTator, which allowed the use of pre-annotations as a
              pre-step to manual annotations. Fourteen annotators were randomly
              paired and differing annotations were discussed for reaching a
              consensus in two annotation phases. In this setting, a high
              inter-annotator agreement was observed. Finally, all results were
              checked against annotations of the rest of the corpus to assure
              corpus-wide consistency. The public release of the NCBI disease
              corpus contains 6892 disease mentions, which are mapped to 790
              unique disease concepts. Of these, 88\% link to a MeSH
              identifier, while the rest contain an OMIM identifier. We were
              able to link 91\% of the mentions to a single disease concept,
              while the rest are described as a combination of concepts. In
              order to help researchers use the corpus to design and test
              disease identification methods, we have prepared the corpus as
              training, testing and development sets. To demonstrate its
              utility, we conducted a benchmarking experiment where we compared
              three different knowledge-based disease normalization methods
              with a best performance in F-measure of 63.7\%. These results
              show that the NCBI disease corpus has the potential to
              significantly improve the state-of-the-art in disease name
              recognition and normalization research, by providing a
              high-quality gold standard thus enabling the development of
              machine-learning based approaches for such tasks. The NCBI
              disease corpus, guidelines and other associated resources are
              available at:
              http://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/.",
  journal  = "J. Biomed. Inform.",
  volume   =  47,
  pages    = "1--10",
  month    =  feb,
  year     =  2014,
  keywords = "Corpus annotation; Disease name corpus; Disease name
              normalization; Disease name recognition; Named entity recognition",
  language = "en"
}
